{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resume file\n",
      "name text\n",
      "email email\n",
      "phone text\n",
      "location text\n",
      "selectedLocation hidden\n",
      "org text\n",
      "cards[a6a97378-59b0-421f-a4c9-76737b41fee1][baseTemplate] hidden\n",
      "cards[a6a97378-59b0-421f-a4c9-76737b41fee1][field0] radio\n",
      "cards[a6a97378-59b0-421f-a4c9-76737b41fee1][field0] radio\n",
      "cards[cc52355f-705b-40f9-9160-c9ff7fcbf769][baseTemplate] hidden\n",
      "cards[cc52355f-705b-40f9-9160-c9ff7fcbf769][field0] radio\n",
      "cards[cc52355f-705b-40f9-9160-c9ff7fcbf769][field0] radio\n",
      "surveysResponses[fc802a09-b71e-40bd-a979-34722f5246c1][baseTemplate] hidden\n",
      "surveysResponses[fc802a09-b71e-40bd-a979-34722f5246c1][surveyId] hidden\n",
      " hidden\n",
      "surveysResponses[fc802a09-b71e-40bd-a979-34722f5246c1][responses][field0] checkbox\n",
      "surveysResponses[fc802a09-b71e-40bd-a979-34722f5246c1][responses][field0] checkbox\n",
      "surveysResponses[fc802a09-b71e-40bd-a979-34722f5246c1][responses][field0] checkbox\n",
      "surveysResponses[fc802a09-b71e-40bd-a979-34722f5246c1][responses][field0] checkbox\n",
      "surveysResponses[fc802a09-b71e-40bd-a979-34722f5246c1][responses][field0] checkbox\n",
      "surveysResponses[fc802a09-b71e-40bd-a979-34722f5246c1][responses][field0] checkbox\n",
      "surveysResponses[fc802a09-b71e-40bd-a979-34722f5246c1][responses][field0] checkbox\n",
      "surveysResponses[fc802a09-b71e-40bd-a979-34722f5246c1][responses][field0] checkbox\n",
      "surveysResponses[fc802a09-b71e-40bd-a979-34722f5246c1][responses][field0] checkbox\n",
      "surveysResponses[fc802a09-b71e-40bd-a979-34722f5246c1][responses][field1] radio\n",
      "surveysResponses[fc802a09-b71e-40bd-a979-34722f5246c1][responses][field1] radio\n",
      "surveysResponses[fc802a09-b71e-40bd-a979-34722f5246c1][responses][field1] radio\n",
      "accountId hidden\n",
      "linkedInData hidden\n",
      "origin hidden\n",
      "referer hidden\n",
      "socialReferralKey hidden\n",
      "socialSource hidden\n",
      "resumeStorageId hidden\n",
      "h-captcha-response hidden\n",
      "source hidden\n",
      "consent[marketing] hidden\n",
      "consent[marketing] checkbox\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://jobs.lever.co/ekimetrics/c62e4fd4-acd5-4860-857a-15a6797696be/apply'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Find all form inputs\n",
    "form_inputs = soup.find_all('input')\n",
    "for input_field in form_inputs:\n",
    "    print(input_field.get('name'), input_field.get('type'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': None, 'phone': None, 'location': None, 'org': None}\n"
     ]
    }
   ],
   "source": [
    "dict = {}\n",
    "\n",
    "for input_field in form_inputs:\n",
    "    if input_field.get('type') == 'text':\n",
    "        dict[input_field.get('name')] = input_field.get('value')\n",
    "\n",
    "print(dict)\n",
    "dict[\"name\"]= \"Wandrille\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DynamicFormClass = type(\n",
    "    'DynamicForm',  # Class name\n",
    "    (object,),      # Base classes\n",
    "    dict     # Dictionary of attributes\n",
    ")\n",
    "\n",
    "# Instantiate the class\n",
    "form_instance = DynamicFormClass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wandrille'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "form_instance.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.prompts import SystemMessagePromptTemplate\n",
    "from langchain_core.prompts import HumanMessagePromptTemplate\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_llama3() -> Ollama:\n",
    "    \"\"\"\n",
    "    Load the LLAMA3 model from OLLAMA.\n",
    "    \"\"\"\n",
    "\n",
    "    ollama_client = Ollama(base_url=\"http://localhost:11434\", model=\"llama3\")\n",
    "\n",
    "    system_message = (\"\"\"\n",
    "        You are an expert AI data extraction assistant specialized in processing text-based information. \n",
    "        Your primary objective is to accurately analyze input text and extract structured information.\n",
    "\n",
    "        Key Guidelines:\n",
    "        - Extract information precisely from the given text\n",
    "        - Be concise and accurate\n",
    "        - Use null for missing information\n",
    "        - Ensure output is valid, parseable JSON\n",
    "        - Do not invent or assume information not present in the text\"\"\")\n",
    "\n",
    "    SystemMessagePromptTemplate(\n",
    "        prompt=PromptTemplate(\n",
    "            input_variables=[],  # No input variables for the system message\n",
    "            template=system_message,\n",
    "        )\n",
    "    )\n",
    "    HumanMessagePromptTemplate(\n",
    "        prompt=PromptTemplate(input_variables=[\"input\"], template=\"{input}\")\n",
    "    )\n",
    "\n",
    "    return ollama_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "\n",
    "def generate_answer_ollama(\n",
    "    input_text: str,\n",
    "    dict: Dict[str, str],\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Generate a summary for a given text using the OLLAMA model.\n",
    "    \"\"\"\n",
    "\n",
    "    ollama_model = load_llama3()\n",
    "\n",
    "    aux_prompt = \"\"\n",
    "    for key, value in dict.items():\n",
    "        aux_prompt += f'{key}: <extracted {key} or null>,'\n",
    "    prompt = f'''\n",
    "    Task: Extract information from the following text and format the response EXACTLY as specified.\n",
    "\n",
    "    Input: {input_text}\n",
    "\n",
    "    STRICT OUTPUT REQUIREMENTS:\n",
    "    1. You MUST respond ONLY in the following JSON format:\n",
    "    {{{aux_prompt}}}\n",
    "\n",
    "    CRITICAL INSTRUCTIONS:\n",
    "    - If ANY information is missing, use null\n",
    "    - Do NOT add ANY additional text or explanation\n",
    "    - The output MUST be a valid JSON that can be parsed directly\n",
    "    - Be precise in extraction\n",
    "    - Only use information explicitly mentioned in the text\n",
    "\n",
    "    EXAMPLE FORMAT:\n",
    "    {{{aux_prompt}}}\n",
    "\n",
    "    Respond ONLY with the JSON, exactly matching this structure.'''\n",
    "    \n",
    "    response = ollama_model(prompt)\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = generate_answer_ollama(\"I am Wandrille, a data scientist. I am very motivated to work with you.\", dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{ \\n  \"name\": \"Wandrille\", \\n  \"phone\": null, \\n  \"location\": null, \\n  \"org\": \"data scientist\" \\n}'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.loads(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Wandrille', 'phone': None, 'location': None, 'org': 'data scientist'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
